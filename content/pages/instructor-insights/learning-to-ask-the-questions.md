---
content_type: page
description: In this section, Michael Short shares his insights about teaching students
  to engage in open-ended problem solving.
layout: instructor_insights
learning_resource_types: []
ocw_type: CourseSection
parent_title: Instructor Insights
parent_type: ThisCourseAtMITSection
parent_uid: 2d14bffe-dd63-6c9b-d719-7e8d00556326
title: Learning to Ask the Questions
uid: 98971248-f330-c89d-5a34-f4974c4a6f72
---

_In this section, Michael Short shares his insights about teaching students to engage in open-ended problem solving._

Many students at MIT are accustomed to answering questions very quickly. They’ve achieved academically—many becoming valedictorians—by answering the hardest math problems the fastest. But when you ask them, instead, “What are the questions you should be asking?” the scenario becomes completely open-ended. Open-ended problem solving is not a skill most students have developed. Turning the question around takes the smartest students and puts them right back in the pack with everyone else. They don’t like this, at first. But it’s very empowering once they learn how to ask the important questions.

I prepare them for open-ended problem solving by posing questions that require students to ask more questions about the data. For example, I might ask something like, “When was this mystery source calibrated?” And the answer is not just “March 2011.” Rather, the answer is, “Well, there’s only one significant figure on the activity stamp, so the activity could be between plus or minus 50%.” Students need to know the minimum and maximum dates on which this source could have been calibrated. The correct answer is that it could have been calibrated in the future given the precision that the scientists put on the activity of the source. So it's not just “answer the question;” rather, it's “what data is missing that would enable you to answer the question with confidence and with accuracy?”

{{< quote "I prepare them for open-ended problem solving by posing questions that require students to ask more questions about the data." "—Michael Short" >}}

In fact, one of the main objectives for the course was for students to learn how to ask questions, such as “How long do you have to sit there and count before you're satisfied with the answer?” And “What do you mean by satisfied? How do you quantify your satisfaction?” I used questions strategically to prompt students to think about confidence intervals. I asked, “Are you 95% confident in your answer?” That was a tip-off to say, “Well, what’s the 2 sigma of your background distribution?” Students realize that they can’t just sit there and count background radiation for 30 seconds. If you actually did the count rate math, it would take 17 minutes! That got them thinking, “If that’s true, how can we really be sure about any measurement?”

It’s not usual for students to resist initially open-ended problem solving. But if they don’t fully engage in the process when going through the activities, they usually get a low grade on the assessment. This is a way for me to communicate, “I told you you'd have to think about this, and instead you blasted through deterministically, not probabilistically. Your grade reflects the fact that you have the right answer, but without the right confidence.” Fortunately, that didn’t happen often because I constantly reinforced the need to engage in open-ended problem solving throughout the course.